{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qhG5FCnfgn7"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  arxiv\n",
        "%pip install langchain-openai\n",
        "%pip install langchain\n",
        "%pip install langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.utilities import ArxivAPIWrapper\n",
        "\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "dYl3uF0BfihY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "7MuC8DcbljyE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(api_key, temperature=0.0)\n",
        "tools = load_tools([\"arxiv\"])"
      ],
      "metadata": {
        "id": "AejCFd7-hEHP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"hwchase17/react\")"
      ],
      "metadata": {
        "id": "FqioutzWhNBP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_identifier = '2405.00522'"
      ],
      "metadata": {
        "id": "NG65WJz2t1-P"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "jXC0HX5dhM9S"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": f\"What's the paper {arxiv_identifier} about?\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85Er2oR6qAcK",
        "outputId": "cb6e8934-fb15-4982-d3fb-b7a60041e77a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use arxiv to search for the paper with the identifier 2405.00522.\n",
            "Action: arxiv\n",
            "Action Input: 2405.00522\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2024-05-01\n",
            "Title: DAM: A Universal Dual Attention Mechanism for Multimodal Timeseries Cryptocurrency Trend Forecasting\n",
            "Authors: Yihang Fu, Mingyu Zhou, Luyao Zhang\n",
            "Summary: In the distributed systems landscape, Blockchain has catalyzed the rise of\n",
            "cryptocurrencies, merging enhanced security and decentralization with\n",
            "significant investment opportunities. Despite their potential, current research\n",
            "on cryptocurrency trend forecasting often falls short by simplistically merging\n",
            "sentiment data without fully considering the nuanced interplay between\n",
            "financial market dynamics and external sentiment influences. This paper\n",
            "presents a novel Dual Attention Mechanism (DAM) for forecasting cryptocurrency\n",
            "trends using multimodal time-series data. Our approach, which integrates\n",
            "critical cryptocurrency metrics with sentiment data from news and social media\n",
            "analyzed through CryptoBERT, addresses the inherent volatility and prediction\n",
            "challenges in cryptocurrency markets. By combining elements of distributed\n",
            "systems, natural language processing, and financial forecasting, our method\n",
            "outperforms conventional models like LSTM and Transformer by up to 20\\% in\n",
            "prediction accuracy. This advancement deepens the understanding of distributed\n",
            "systems and has practical implications in financial markets, benefiting\n",
            "stakeholders in cryptocurrency and blockchain technologies. Moreover, our\n",
            "enhanced forecasting approach can significantly support decentralized science\n",
            "(DeSci) by facilitating strategic planning and the efficient adoption of\n",
            "blockchain technologies, improving operational efficiency and financial risk\n",
            "management in the rapidly evolving digital asset domain, thus ensuring optimal\n",
            "resource allocation.\u001b[0m\u001b[32;1m\u001b[1;3mThe paper 2405.00522 is about a Dual Attention Mechanism for Multimodal Timeseries Cryptocurrency Trend Forecasting.\n",
            "Final Answer: The paper 2405.00522 is about DAM: A Universal Dual Attention Mechanism for Multimodal Timeseries Cryptocurrency Trend Forecasting.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What's the paper 2405.00522 about?\",\n",
              " 'output': 'The paper 2405.00522 is about DAM: A Universal Dual Attention Mechanism for Multimodal Timeseries Cryptocurrency Trend Forecasting.'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv = ArxivAPIWrapper()\n",
        "docs = arxiv.run(arxiv_identifier)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Def12GGjq2Tp",
        "outputId": "c4a7f849-5728-4e89-95db-00e680e2670f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Published: 2024-05-01\\nTitle: DAM: A Universal Dual Attention Mechanism for Multimodal Timeseries Cryptocurrency Trend Forecasting\\nAuthors: Yihang Fu, Mingyu Zhou, Luyao Zhang\\nSummary: In the distributed systems landscape, Blockchain has catalyzed the rise of\\ncryptocurrencies, merging enhanced security and decentralization with\\nsignificant investment opportunities. Despite their potential, current research\\non cryptocurrency trend forecasting often falls short by simplistically merging\\nsentiment data without fully considering the nuanced interplay between\\nfinancial market dynamics and external sentiment influences. This paper\\npresents a novel Dual Attention Mechanism (DAM) for forecasting cryptocurrency\\ntrends using multimodal time-series data. Our approach, which integrates\\ncritical cryptocurrency metrics with sentiment data from news and social media\\nanalyzed through CryptoBERT, addresses the inherent volatility and prediction\\nchallenges in cryptocurrency markets. By combining elements of distributed\\nsystems, natural language processing, and financial forecasting, our method\\noutperforms conventional models like LSTM and Transformer by up to 20\\\\% in\\nprediction accuracy. This advancement deepens the understanding of distributed\\nsystems and has practical implications in financial markets, benefiting\\nstakeholders in cryptocurrency and blockchain technologies. Moreover, our\\nenhanced forecasting approach can significantly support decentralized science\\n(DeSci) by facilitating strategic planning and the efficient adoption of\\nblockchain technologies, improving operational efficiency and financial risk\\nmanagement in the rapidly evolving digital asset domain, thus ensuring optimal\\nresource allocation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = arxiv.run(\"Yihang Fu\")\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "e605pizrsien",
        "outputId": "1398bcb4-2315-4936-c567-3738aafa6055"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Published: 2024-03-17\\nTitle: Phasic Diversity Optimization for Population-Based Reinforcement Learning\\nAuthors: Jingcheng Jiang, Haiyin Piao, Yu Fu, Yihang Hao, Chuanlu Jiang, Ziqi Wei, Xin Yang\\nSummary: Reviewing the previous work of diversity Rein-forcement Learning,diversity is\\noften obtained via an augmented loss function,which requires a balance between\\nreward and diversity.Generally,diversity optimization algorithms use\\nMulti-armed Bandits algorithms to select the coefficient in the pre-defined\\nspace. However, the dynamic distribution of reward signals for MABs or the\\nconflict between quality and diversity limits the performance of these methods.\\nWe introduce the Phasic Diversity Optimization (PDO) algorithm, a\\nPopulation-Based Training framework that separates reward and diversity\\ntraining into distinct phases instead of optimizing a multi-objective function.\\nIn the auxiliary phase, agents with poor performance diversified via\\ndeterminants will not replace the better agents in the archive. The decoupling\\nof reward and diversity allows us to use an aggressive diversity optimization\\nin the auxiliary phase without performance degradation. Furthermore, we\\nconstruct a dogfight scenario for aerial agents to demonstrate the practicality\\nof the PDO algorithm. We introduce two implementations of PDO archive and\\nconduct tests in the newly proposed adversarial dogfight and MuJoCo\\nsimulations. The results show that our proposed algorithm achieves better\\nperformance than baselines.\\n\\nPublished: 2020-03-20\\nTitle: Hybrid aerial ground locomotion with a single passive wheel\\nAuthors: Youming Qin, Yihang Li, Xu Wei, Fu Zhang\\nSummary: Exploiting contacts with environment structures provides extra force support\\nto a UAV, often reducing the power consumption and hence extending the mission\\ntime. This paper investigates one such way to exploit flat surfaces in the\\nenvironment by a novel aerial-ground hybrid locomotion. Our design is a single\\npassive wheel integrated at the UAV bottom, serving a minimal design to date.\\nWe present the principle and implementation of such a simple design as well as\\nits control. Flight experiments are conducted to verify the feasibility and the\\npower saving caused by the ground locomotion. Results show that our minimal\\ndesign allows successful aerial-ground hybrid locomotion even with a\\nless-controllable bi-copter UAV. The ground locomotion saves up to 77% battery\\nwithout much tuning effort.\\n\\nPublished: 2021-09-29\\nTitle: Segmentation of Roads in Satellite Images using specially modified U-Net CNNs\\nAuthors: Jonas Bokstaller, Yihang She, Zhehan Fu, Tommaso Macrì\\nSummary: The image classification problem has been deeply investigated by the research\\ncommunity, with computer vision algorithms and with the help of Neural\\nNetworks. The aim of this paper is to build an image classifier for satellite\\nimages of urban scenes that identifies the portions of the images in which a\\nroad is located, separating these portions from the rest. Unlike conventional\\ncomputer vision algorithms, convolutional neural networks (CNNs) provide\\naccurate and reliable results on this task. Our novel approach uses a sliding\\nwindow to extract patches out of the whole image, data augmentation for\\ngenerating more training/testing data and lastly a series of specially modified\\nU-Net CNNs. This proposed technique outperforms all other baselines tested in\\nterms of mean F-score metric.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1sFNPUnos2cR"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}